name: benchmark

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:

permissions:
  # deployments permission to deploy GitHub pages website
  deployments: write
  # contents permission to update benchmark contents in gh-pages branch
  contents: write

jobs:
  benchmark:
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
      - uses: actions/checkout@v3
      - uses: pnpm/action-setup@v2
      - uses: actions/setup-node@v3
        with:
          # Fix the version to stabilize results.
          node-version: 16.14.0
          cache: 'pnpm'

      - run: pnpm install

      - name: pnpm run build
        run: pnpm run build

      - name: Install valgrind
        run: sudo apt install -y valgrind

      - name: Setup cachegrind-benchmarking
        run: node benchmark/setup-cachegrind-benchmarking.js

      - name: Run cachegrind-benchmarking
        run: |
          # NOTE: Some options are passed to the node command to get consistent results.
          # ref: https://pythonspeed.com/articles/consistent-benchmarking-in-ci/#consistent-benchmarking-is-hard-and-its-even-harder-in-the-cloud
          # ref: https://github.com/v8/v8/blob/d55d51a2427b5c60b94cf5a9f2bbfbacdfe19b8c/src/flags/flag-definitions.h#L2349-L2372
          RESULT=$( \
            python3 \
              third-party/cachegrind-benchmarking/cachegrind.py \
              node \
                --random-gc-interval=0 \
                --no-randomize-all-allocations \
                --hash-seed=0 \
                --random-seed=0 \
                --fuzzer-random-seed=0 \
                --no-turbo-stress-instruction-scheduling \
                --no-stress-compaction-random \
                --predictable \
                --predictable-gc-schedule \
                benchmark/run-cachegrind-benchmarking.js \
          )
          echo \
            \{ \
              \"name\": \"cachegrind-benchmarking-1\", \
              \"unit\": \"instructions\", \
              \"value\": $RESULT \
            \} \
            >> benchmark/result.jsonl

      - name: Run cachegrind-benchmarking
        run: |
          # NOTE: Some options are passed to the node command to get consistent results.
          # ref: https://pythonspeed.com/articles/consistent-benchmarking-in-ci/#consistent-benchmarking-is-hard-and-its-even-harder-in-the-cloud
          # ref: https://github.com/v8/v8/blob/d55d51a2427b5c60b94cf5a9f2bbfbacdfe19b8c/src/flags/flag-definitions.h#L2349-L2372
          RESULT=$( \
            python3 \
              third-party/cachegrind-benchmarking/cachegrind.py \
              node \
                --random-gc-interval=0 \
                --no-randomize-all-allocations \
                --hash-seed=0 \
                --random-seed=0 \
                --fuzzer-random-seed=0 \
                --no-turbo-stress-instruction-scheduling \
                --no-stress-compaction-random \
                --predictable \
                --predictable-gc-schedule \
                benchmark/run-cachegrind-benchmarking.js \
          )
          echo \
            \{ \
              \"name\": \"cachegrind-benchmarking-2\", \
              \"unit\": \"instructions\", \
              \"value\": $RESULT \
            \} \
            >> benchmark/result.jsonl

      - name: Run cachegrind-benchmarking
        run: |
          # NOTE: Some options are passed to the node command to get consistent results.
          # ref: https://pythonspeed.com/articles/consistent-benchmarking-in-ci/#consistent-benchmarking-is-hard-and-its-even-harder-in-the-cloud
          # ref: https://github.com/v8/v8/blob/d55d51a2427b5c60b94cf5a9f2bbfbacdfe19b8c/src/flags/flag-definitions.h#L2349-L2372
          RESULT=$( \
            python3 \
              third-party/cachegrind-benchmarking/cachegrind.py \
              node \
                --random-gc-interval=0 \
                --no-randomize-all-allocations \
                --hash-seed=0 \
                --random-seed=0 \
                --fuzzer-random-seed=0 \
                --no-turbo-stress-instruction-scheduling \
                --no-stress-compaction-random \
                --predictable \
                --predictable-gc-schedule \
                benchmark/run-cachegrind-benchmarking.js \
          )
          echo \
            \{ \
              \"name\": \"cachegrind-benchmarking-3\", \
              \"unit\": \"instructions\", \
              \"value\": $RESULT \
            \} \
            >> benchmark/result.jsonl

      - name: Run cachegrind-benchmarking
        run: |
          # NOTE: Some options are passed to the node command to get consistent results.
          # ref: https://pythonspeed.com/articles/consistent-benchmarking-in-ci/#consistent-benchmarking-is-hard-and-its-even-harder-in-the-cloud
          # ref: https://github.com/v8/v8/blob/d55d51a2427b5c60b94cf5a9f2bbfbacdfe19b8c/src/flags/flag-definitions.h#L2349-L2372
          RESULT=$( \
            python3 \
              third-party/cachegrind-benchmarking/cachegrind.py \
              node \
                --random-gc-interval=0 \
                --no-randomize-all-allocations \
                --hash-seed=0 \
                --random-seed=0 \
                --fuzzer-random-seed=0 \
                --no-turbo-stress-instruction-scheduling \
                --no-stress-compaction-random \
                --predictable \
                --predictable-gc-schedule \
                benchmark/run-cachegrind-benchmarking.js \
          )
          echo \
            \{ \
              \"name\": \"cachegrind-benchmarking-4\", \
              \"unit\": \"instructions\", \
              \"value\": $RESULT \
            \} \
            >> benchmark/result.jsonl

      - name: Run cachegrind-benchmarking
        run: |
          # NOTE: Some options are passed to the node command to get consistent results.
          # ref: https://pythonspeed.com/articles/consistent-benchmarking-in-ci/#consistent-benchmarking-is-hard-and-its-even-harder-in-the-cloud
          # ref: https://github.com/v8/v8/blob/d55d51a2427b5c60b94cf5a9f2bbfbacdfe19b8c/src/flags/flag-definitions.h#L2349-L2372
          RESULT=$( \
            python3 \
              third-party/cachegrind-benchmarking/cachegrind.py \
              node \
                --random-gc-interval=0 \
                --no-randomize-all-allocations \
                --hash-seed=0 \
                --random-seed=0 \
                --fuzzer-random-seed=0 \
                --no-turbo-stress-instruction-scheduling \
                --no-stress-compaction-random \
                --predictable \
                --predictable-gc-schedule \
                benchmark/run-cachegrind-benchmarking.js \
          )
          echo \
            \{ \
              \"name\": \"cachegrind-benchmarking-5\", \
              \"unit\": \"instructions\", \
              \"value\": $RESULT \
            \} \
            >> benchmark/result.jsonl

      - name: Run cachegrind-benchmarking
        run: |
          # NOTE: Some options are passed to the node command to get consistent results.
          # ref: https://pythonspeed.com/articles/consistent-benchmarking-in-ci/#consistent-benchmarking-is-hard-and-its-even-harder-in-the-cloud
          # ref: https://github.com/v8/v8/blob/d55d51a2427b5c60b94cf5a9f2bbfbacdfe19b8c/src/flags/flag-definitions.h#L2349-L2372
          RESULT=$( \
            python3 \
              third-party/cachegrind-benchmarking/cachegrind.py \
              node \
                --random-gc-interval=0 \
                --no-randomize-all-allocations \
                --hash-seed=0 \
                --random-seed=0 \
                --fuzzer-random-seed=0 \
                --no-turbo-stress-instruction-scheduling \
                --no-stress-compaction-random \
                --predictable \
                --predictable-gc-schedule \
                benchmark/run-cachegrind-benchmarking.js \
          )
          echo \
            \{ \
              \"name\": \"cachegrind-benchmarking-6\", \
              \"unit\": \"instructions\", \
              \"value\": $RESULT \
            \} \
            >> benchmark/result.jsonl

      - name: Run cachegrind-benchmarking
        run: |
          # NOTE: Some options are passed to the node command to get consistent results.
          # ref: https://pythonspeed.com/articles/consistent-benchmarking-in-ci/#consistent-benchmarking-is-hard-and-its-even-harder-in-the-cloud
          # ref: https://github.com/v8/v8/blob/d55d51a2427b5c60b94cf5a9f2bbfbacdfe19b8c/src/flags/flag-definitions.h#L2349-L2372
          RESULT=$( \
            python3 \
              third-party/cachegrind-benchmarking/cachegrind.py \
              node \
                --random-gc-interval=0 \
                --no-randomize-all-allocations \
                --hash-seed=0 \
                --random-seed=0 \
                --fuzzer-random-seed=0 \
                --no-turbo-stress-instruction-scheduling \
                --no-stress-compaction-random \
                --predictable \
                --predictable-gc-schedule \
                benchmark/run-cachegrind-benchmarking.js \
          )
          echo \
            \{ \
              \"name\": \"cachegrind-benchmarking-7\", \
              \"unit\": \"instructions\", \
              \"value\": $RESULT \
            \} \
            >> benchmark/result.jsonl

      - name: Run cachegrind-benchmarking
        run: |
          # NOTE: Some options are passed to the node command to get consistent results.
          # ref: https://pythonspeed.com/articles/consistent-benchmarking-in-ci/#consistent-benchmarking-is-hard-and-its-even-harder-in-the-cloud
          # ref: https://github.com/v8/v8/blob/d55d51a2427b5c60b94cf5a9f2bbfbacdfe19b8c/src/flags/flag-definitions.h#L2349-L2372
          RESULT=$( \
            python3 \
              third-party/cachegrind-benchmarking/cachegrind.py \
              node \
                --random-gc-interval=0 \
                --no-randomize-all-allocations \
                --hash-seed=0 \
                --random-seed=0 \
                --fuzzer-random-seed=0 \
                --no-turbo-stress-instruction-scheduling \
                --no-stress-compaction-random \
                --predictable \
                --predictable-gc-schedule \
                benchmark/run-cachegrind-benchmarking.js \
          )
          echo \
            \{ \
              \"name\": \"cachegrind-benchmarking-8\", \
              \"unit\": \"instructions\", \
              \"value\": $RESULT \
            \} \
            >> benchmark/result.jsonl

      - name: Run cachegrind-benchmarking
        run: |
          # NOTE: Some options are passed to the node command to get consistent results.
          # ref: https://pythonspeed.com/articles/consistent-benchmarking-in-ci/#consistent-benchmarking-is-hard-and-its-even-harder-in-the-cloud
          # ref: https://github.com/v8/v8/blob/d55d51a2427b5c60b94cf5a9f2bbfbacdfe19b8c/src/flags/flag-definitions.h#L2349-L2372
          RESULT=$( \
            python3 \
              third-party/cachegrind-benchmarking/cachegrind.py \
              node \
                --random-gc-interval=0 \
                --no-randomize-all-allocations \
                --hash-seed=0 \
                --random-seed=0 \
                --fuzzer-random-seed=0 \
                --no-turbo-stress-instruction-scheduling \
                --no-stress-compaction-random \
                --predictable \
                --predictable-gc-schedule \
                benchmark/run-cachegrind-benchmarking.js \
          )
          echo \
            \{ \
              \"name\": \"cachegrind-benchmarking-9\", \
              \"unit\": \"instructions\", \
              \"value\": $RESULT \
            \} \
            >> benchmark/result.jsonl

      - name: Run cachegrind-benchmarking
        run: |
          # NOTE: Some options are passed to the node command to get consistent results.
          # ref: https://pythonspeed.com/articles/consistent-benchmarking-in-ci/#consistent-benchmarking-is-hard-and-its-even-harder-in-the-cloud
          # ref: https://github.com/v8/v8/blob/d55d51a2427b5c60b94cf5a9f2bbfbacdfe19b8c/src/flags/flag-definitions.h#L2349-L2372
          RESULT=$( \
            python3 \
              third-party/cachegrind-benchmarking/cachegrind.py \
              node \
                --random-gc-interval=0 \
                --no-randomize-all-allocations \
                --hash-seed=0 \
                --random-seed=0 \
                --fuzzer-random-seed=0 \
                --no-turbo-stress-instruction-scheduling \
                --no-stress-compaction-random \
                --predictable \
                --predictable-gc-schedule \
                benchmark/run-cachegrind-benchmarking.js \
          )
          echo \
            \{ \
              \"name\": \"cachegrind-benchmarking-10\", \
              \"unit\": \"instructions\", \
              \"value\": $RESULT \
            \} \
            >> benchmark/result.jsonl

      - name: Convert jsonl to json
        run: jq -s '.' benchmark/result.jsonl > benchmark/result.json

      - name: Upload benchmark
        uses: benchmark-action/github-action-benchmark@v1
        with:
          tool: customSmallerIsBetter
          output-file-path: benchmark/result.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: ${{ github.ref == 'refs/heads/main' }}
          comment-on-alert: true
          fail-on-alert: true
          # There is always an error of about 5%.
          # Considering this, the alert threshold is set at 30%.
          alert-threshold: '130%'
          # for test
          comment-always: true
